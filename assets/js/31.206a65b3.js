(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{356:function(t,o,e){"use strict";e.r(o);var i=e(18),a=Object(i.a)({},(function(){var t=this,o=t._self._c;return o("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[o("h1",{attrs:{id:"google-ai-studio-полное-руководство-на-ноябрь-2025-года-мощныи-инструмент-для-работы-с-gemini"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#google-ai-studio-полное-руководство-на-ноябрь-2025-года-мощныи-инструмент-для-работы-с-gemini"}},[t._v("#")]),t._v(" Google AI Studio: Полное руководство на ноябрь 2025 года - Мощный инструмент для работы с Gemini")]),t._v(" "),o("p",[t._v("Google AI Studio представляет собой веб-базированную интегрированную среду разработки (IDE), специально разработанную Google для прототипирования приложений с использованием моделей Gemini и других генеративных AI моделей[1][3][10]. На ноябрь 2025 года Google AI Studio позиционирует себя как "),o("strong",[t._v("самый быстрый способ начать работу с Gemini")]),t._v(", предоставляя бесплатный доступ к передовым AI моделям без необходимости кодирования, сложной конфигурации или активации биллинга[1][10][16]. Платформа была запущена в декабре 2023 года как преемница Google MakerSuite, унаследовав её функциональность, но значительно расширив возможности для работы с новым поколением Gemini моделей[3]. Сегодня Google AI Studio служит не просто инструментом экспериментирования, а полноценной платформой для создания, тестирования и развертывания AI-приложений, с интеграцией в Google Cloud, поддержкой мультимодальных входов (текст, изображения, видео, аудио) и прямым развертыванием в облако.")]),t._v(" "),o("h2",{attrs:{id:"история-развития-и-позиционирование-в-экосистеме-google"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#история-развития-и-позиционирование-в-экосистеме-google"}},[t._v("#")]),t._v(" История развития и позиционирование в экосистеме Google")]),t._v(" "),o("p",[t._v("Google AI Studio эволюционировала из MakerSuite, инструмента, представленного на Google I/O в мае 2023 года для работы с моделью PaLM[3]. Однако с запуском Gemini в декабре 2023 года Google решила полностью переориентировать платформу вокруг нового поколения мультимодальных моделей[3][10]. Это переоснащение было стратегическим, поскольку Google понимала, что "),o("strong",[t._v("Gemini представляет качественный скачок")]),t._v(" в возможностях генеративного AI, требующий инструментов, которые полностью раскроют её потенциал[3].")]),t._v(" "),o("p",[t._v("На ноябрь 2025 года Google AI Studio находится в центре стратегии Google по демократизации AI[7][40][43]. Компания недавно представила несколько ключевых инициатив, включая "),o("strong",[t._v("Google Antigravity")]),t._v(" — новую агентивную платформу разработки, которая работает в тесной интеграции с AI Studio[7][40]. Кроме того, Google выпустила "),o("strong",[t._v("Gemini 3")]),t._v(" — свою самую продвинутую модель, которая доступна через AI Studio с первого дня[7][40]. Это демонстрирует, что Google рассматривает AI Studio как первостепенный канал для распространения своих моделей, наравне с мобильными приложениями и интеграциями в Google Workspace[43].")]),t._v(" "),o("h2",{attrs:{id:"что-такое-google-ai-studio-архитектура-и-основные-компоненты"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#что-такое-google-ai-studio-архитектура-и-основные-компоненты"}},[t._v("#")]),t._v(" Что такое Google AI Studio: Архитектура и основные компоненты")]),t._v(" "),o("p",[t._v("Google AI Studio представляет собой облачную платформу, доступную через браузер, которая позволяет пользователям взаимодействовать с моделями Gemini без необходимости установки программного обеспечения или управления облачной инфраструктурой[1][10][16]. На техническом уровне, AI Studio "),o("strong",[t._v("действует как фронтенд для Gemini API")]),t._v(", предоставляя удобный интерфейс для тестирования промптов, изучения возможностей моделей и генерирования кода для использования в собственных приложениях[16][34][41].")]),t._v(" "),o("p",[t._v("Архитектурно, Google AI Studio состоит из нескольких ключевых компонентов[2][10]:")]),t._v(" "),o("p",[o("strong",[t._v("Интерфейс промптирования")]),t._v(" позволяет пользователям создавать и тестировать различные типы промптов — от простых чат-взаимодействий до сложных структурированных выходов[2][10]. Каждый тип промпта оптимизирован для конкретного use case[2].")]),t._v(" "),o("p",[o("strong",[t._v("Панель параметров запуска (Run Settings)")]),t._v(" предоставляет гранулярный контроль над поведением модели, включая температуру, количество ответов, параметры безопасности, сооружение, выполнение кода и другие опции[2][16][49].")]),t._v(" "),o("p",[o("strong",[t._v("Интегрированный API браузер")]),t._v(" позволяет пользователям не-разработчикам тестировать API вызовы непосредственно в интерфейсе, затем сгенерировать рабочий код на выбранном языке программирования[2][16].")]),t._v(" "),o("p",[o("strong",[t._v("Система управления проектами")]),t._v(" позволяет организовать промпты и приложения по проектам, упрощая управление множественными разработками[10][41].")]),t._v(" "),o("p",[o("strong",[t._v("Интеграция с облаком")]),t._v(" позволяет развертывать приложения, построенные в AI Studio, прямо в Google Cloud Run одним нажатием кнопки, получая стабильный HTTPS эндпоинт без необходимости управления контейнерами или Kubernetes[30][43].")]),t._v(" "),o("h2",{attrs:{id:"семеиство-gemini-моделеи-доступных-в-ai-studio-на-ноябрь-2025-года"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#семеиство-gemini-моделеи-доступных-в-ai-studio-на-ноябрь-2025-года"}},[t._v("#")]),t._v(" Семейство Gemini моделей, доступных в AI Studio на ноябрь 2025 года")]),t._v(" "),o("p",[t._v("На ноябрь 2025 года Google AI Studio предоставляет доступ к полному спектру Gemini моделей, каждая оптимизирована для различных сценариев использования[52][53]:")]),t._v(" "),o("p",[o("strong",[t._v("Gemini 3 Pro")]),t._v(" — флагманская модель Google, выпущенная в 2025 году, представляет "),o("strong",[t._v("самую интеллектуальную модель в своей линейке")]),t._v('[7][40][52]. Gemini 3 Pro содержит 1 миллион токенов входного контекста и до 64,000 токенов выхода[52]. Модель особенно сильна в многошаговом рассуждении, создании кода, мультимодальном понимании и агентивных задачах[7][40]. Gemini 3 Pro использует динамическое мышление по умолчанию, означающее, что модель интернально рассуждает о вашем запросе перед формированием ответа[52]. Для быстрых ответов, когда сложное рассуждение не требуется, вы можете установить уровень мышления на "low" для снижения задержки[52].')]),t._v(" "),o("p",[o("strong",[t._v("Gemini 2.5 Pro")]),t._v(" является универсальной моделью для большинства задач, предлагающей хороший баланс между производительностью, скоростью и стоимостью[52][53]. Она поддерживает все те же мультимодальные возможности, что и Gemini 3, но может быть более быстрой в некоторых случаях[52].")]),t._v(" "),o("p",[o("strong",[t._v("Gemini 2.5 Flash")]),t._v(" позиционируется как "),o("strong",[t._v("лучшая модель по соотношению цены и производительности")]),t._v(', оптимизированная для скорости при сохранении качества[52][53][56]. Gemini 2.5 Flash особенно хороша для высокопроизводительных задач, требующих низкой задержки, обработки больших объемов данных и задач, требующих рассуждения[52][56]. Модель может контролировать "бюджет мышления", позволяя разработчикам балансировать между задержкой и качеством рассуждения[56].')]),t._v(" "),o("p",[o("strong",[t._v("Gemini 2.5 Flash-Lite")]),t._v(" — самая быстрая модель в линейке, оптимизированная для предельной экономичности и высокой пропускной способности[52][53]. Эта модель идеальна для простых задач, обработки больших объемов запросов в реальном времени и ситуаций, где стоимость является приоритетом[52].")]),t._v(" "),o("p",[o("strong",[t._v("Gemini 2.0 Flash")]),t._v(" остается доступной как второе поколение рабочей лошадки Google, поддерживающей 1 миллион токенов входного контекста[52][53]. Хотя она менее мощна, чем новые модели, она все еще является надежным выбором для большинства задач[52].")]),t._v(" "),o("p",[t._v("Для специализированных задач доступны также "),o("strong",[t._v("специализированные варианты")]),t._v(", включая Gemini 2.5 Flash-Image для работы с изображениями, Gemini 2.5 Flash-TTS для синтеза речи и другие модели[52][53].")]),t._v(" "),o("h2",{attrs:{id:"начало-работы-интерфеис-и-первые-шаги"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#начало-работы-интерфеис-и-первые-шаги"}},[t._v("#")]),t._v(" Начало работы: Интерфейс и первые шаги")]),t._v(" "),o("p",[t._v("Доступ к Google AI Studio получить исключительно просто[1][10][16]. Откройте браузер, перейдите на aistudio.google.com, и войдите со своей Google учетной записью[1][10]. Никакой регистрации, кредитной карты или сложной настройки не требуется для начала работы[1][16].")]),t._v(" "),o("p",[t._v("После входа вы видите основной интерфейс, который разделен на несколько основных секций[2][10][13]:")]),t._v(" "),o("p",[o("strong",[t._v("Левая панель навигации")]),t._v(" содержит основные разделы: Home, Chat, Build, Dashboard и Documentation[13][60]. Home предоставляет быстрый доступ к различным функциям и показывает последние обновления[13][60]. Chat позволяет взаимодействовать с моделью в разговорном режиме[13][60]. Build предоставляет более продвинутые инструменты для создания приложений[13][60]. Dashboard показывает использование API и аналитику[13][60].")]),t._v(" "),o("p",[o("strong",[t._v("Центральная область")]),t._v(" — это основная рабочая область, где вы вводите промпты, настраиваете параметры и видите результаты[2][10][13].")]),t._v(" "),o("p",[o("strong",[t._v("Правая панель")]),t._v(" содержит Run Settings — параметры, управляющие поведением модели[2][16][49]. Здесь вы выбираете модель, устанавливаете температуру, количество ответов, включаете функции вроде кода выполнения, функционального вызова, структурированного выхода и других[2][16][49].")]),t._v(" "),o("p",[t._v("Интерфейс разработан быть максимально простым для начинающих, но содержит достаточно мощности для опытных разработчиков[10][13][34].")]),t._v(" "),o("h2",{attrs:{id:"основные-функции-и-типы-промптов"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#основные-функции-и-типы-промптов"}},[t._v("#")]),t._v(" Основные функции и типы промптов")]),t._v(" "),o("p",[t._v("Google AI Studio предоставляет несколько различных интерфейсов для различных типов взаимодействия с моделью[2][16][49]:")]),t._v(" "),o("h3",{attrs:{id:"chat-prompts-беседа-с-ai"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#chat-prompts-беседа-с-ai"}},[t._v("#")]),t._v(" Chat Prompts: Беседа с AI")]),t._v(" "),o("p",[o("strong",[t._v("Chat Prompts")]),t._v(' позволяют вам взаимодействовать с моделью в многооборотном разговоре[2][16][49]. Вы даете системные инструкции, определяющие поведение модели, затем начинаете диалог[2][16]. Например, вы можете сказать: "Ты помощник, который объясняет сложные концепции программирования простыми словами" и затем задавать вопросы[2][16]. Модель будет отвечать в соответствии с вашей системной инструкцией.')]),t._v(" "),o("p",[t._v("Chat Prompts идеальны для создания chatbot-приложений, виртуальных ассистентов, систем ответов на вопросы и любых других интерактивных приложений[2][16][49].")]),t._v(" "),o("h3",{attrs:{id:"structured-prompts-контролируемыи-выход"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#structured-prompts-контролируемыи-выход"}},[t._v("#")]),t._v(" Structured Prompts: Контролируемый выход")]),t._v(" "),o("p",[o("strong",[t._v("Structured Prompts")]),t._v(" позволяют вам определять точный формат выхода, который вы хотите получить[2][49]. Вместо открытого текста вы можете попросить модель генерировать JSON, CSV или другой структурированный формат[2][49]. Вы предоставляете примеры входа и желаемого выхода, и модель учится следовать этому паттерну[2][49].")]),t._v(" "),o("p",[t._v("Structured Prompts особенно полезны для извлечения информации из документов, обработки бизнес-данных, генерирования каталогов продуктов и других задач, требующих предсказуемого формата[2][49].")]),t._v(" "),o("h3",{attrs:{id:"realtime-streaming-прямая-трансляция"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#realtime-streaming-прямая-трансляция"}},[t._v("#")]),t._v(" Realtime Streaming: Прямая трансляция")]),t._v(" "),o("p",[o("strong",[t._v("Realtime Streaming")]),t._v(" позволяет потокировать видео с вашего экрана или камеры в реальном времени и получать мгновенный анализ от Gemini[5][25]. Это идеально подходит для живого анализа, обучения, демонстраций и интерактивных сессий[5][25].")]),t._v(" "),o("p",[t._v("Например, вы можете демонстрировать использование веб-приложения, и Gemini может предлагать улучшения в реальном времени, или показывать физический объект и получать немедленный анализ[5][25].")]),t._v(" "),o("h3",{attrs:{id:"video-generation-создание-видео"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#video-generation-создание-видео"}},[t._v("#")]),t._v(" Video Generation: Создание видео")]),t._v(" "),o("p",[o("strong",[t._v("Video Generation")]),t._v(" (Veo 3.1) позволяет генерировать видео на основе текстовых описаний[9][57]. Вы описываете видео, которое хотите создать, и Gemini генерирует 8-секундное видео с встроенным звуком[9][57]. Это полностью меняет способ, которым творческие люди работают с видеоматериалами[9][57].")]),t._v(" "),o("h2",{attrs:{id:"расширенные-функции-от-функционального-вызова-к-агентам"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#расширенные-функции-от-функционального-вызова-к-агентам"}},[t._v("#")]),t._v(" Расширенные функции: От функционального вызова к агентам")]),t._v(" "),o("h3",{attrs:{id:"function-calling-интеграция-с-внешними-инструментами"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#function-calling-интеграция-с-внешними-инструментами"}},[t._v("#")]),t._v(" Function Calling: Интеграция с внешними инструментами")]),t._v(" "),o("p",[o("strong",[t._v("Function Calling")]),t._v(" позволяет моделям определять, когда они должны вызвать внешний инструмент или API, и предоставляет необходимые параметры[22]. Вы определяете набор функций, которые модель может вызвать, и затем модель автоматически решает, когда их использовать[22].")]),t._v(" "),o("p",[t._v("Например, вы можете определить функцию "),o("code",[t._v("get_weather(location)")]),t._v(', и когда пользователь спросит "Какая погода в Париже?", модель вызовет эту функцию с параметром "Paris", получит результат, и затем предоставит пользователю естественный ответ[22].')]),t._v(" "),o("p",[t._v("Function Calling поддерживает как последовательный вызов (одна функция вызывает другую), так и параллельный вызов (несколько функций одновременно)[22].")]),t._v(" "),o("h3",{attrs:{id:"grounding-привязка-к-источникам-информации"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#grounding-привязка-к-источникам-информации"}},[t._v("#")]),t._v(" Grounding: Привязка к источникам информации")]),t._v(" "),o("p",[o("strong",[t._v("Grounding")]),t._v(" позволяет привязать выход модели к конкретным источникам информации, значительно снижая галлюцинирование[19][59]. Вы можете заземлять с помощью Google Search, Google Maps, вашей пользовательской базы данных или любого другого источника[19][59].")]),t._v(" "),o("p",[t._v("Когда вы включаете grounding, модель первым образом получает релевантную информацию из источника, затем генерирует ответ на основе этой информации[19][59]. Это означает, что вы получаете более точные, проверяемые ответы с цитатами на источники[19][59].")]),t._v(" "),o("h3",{attrs:{id:"google-search-integration-живая-информация"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#google-search-integration-живая-информация"}},[t._v("#")]),t._v(" Google Search Integration: Живая информация")]),t._v(" "),o("p",[t._v("Google AI Studio может интегрировать Google Search для получения актуальной информации[17][20][23]. Когда вы включаете Web Search, модель может искать в интернете за последние новости, текущие события и информацию, которая может быть вне её обучающих данных[17][20][23].")]),t._v(" "),o("p",[t._v("Это особенно полезно для создания исследовательских ассистентов, новостных приложений, аналитических инструментов и любых других приложений, где требуется текущая информация[17][20][23].")]),t._v(" "),o("h3",{attrs:{id:"code-execution-выполнение-кода-в-песочнице"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#code-execution-выполнение-кода-в-песочнице"}},[t._v("#")]),t._v(" Code Execution: Выполнение кода в песочнице")]),t._v(" "),o("p",[t._v("Google AI Studio поддерживает выполнение Python кода в защищённой песочнице[2][16][49]. Это позволяет моделям писать и тестировать код, выполнять вычисления и проверять результаты без необходимости пользователю копировать код в отдельную среду[2][16][49].")]),t._v(" "),o("p",[t._v('Когда вы просите модель "напиши код для визуализации этих данных", она может написать Python код, выполнить его в песочнице, и показать вам результат с графиком[2][16][49].')]),t._v(" "),o("h2",{attrs:{id:"промпт-инженерия-в-google-ai-studio-лучшие-практики"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#промпт-инженерия-в-google-ai-studio-лучшие-практики"}},[t._v("#")]),t._v(" Промпт-инженерия в Google AI Studio: Лучшие практики")]),t._v(" "),o("p",[t._v("Мастерство написания эффективных промптов является ключом к получению лучших результатов от Gemini[20][23][46]:")]),t._v(" "),o("h3",{attrs:{id:"структурирование-промптов-с-xml-тегами"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#структурирование-промптов-с-xml-тегами"}},[t._v("#")]),t._v(" Структурирование промптов с XML тегами")]),t._v(" "),o("p",[o("strong",[t._v("XML теги и префиксы")]),t._v(" помогают структурировать сложные промпты и делают их понятнее для модели[46]. Вместо беспорядочного текста, используйте структуру вроде[46]:")]),t._v(" "),o("div",{staticClass:"language- line-numbers-mode"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[t._v("<context>\n[Фоновая информация о задаче]\n</context>\n\n<task>\n[Что именно нужно сделать]\n</task>\n\n<constraints>\n[Ограничения и требования]\n</constraints>\n")])]),t._v(" "),o("div",{staticClass:"line-numbers-wrapper"},[o("span",{staticClass:"line-number"},[t._v("1")]),o("br"),o("span",{staticClass:"line-number"},[t._v("2")]),o("br"),o("span",{staticClass:"line-number"},[t._v("3")]),o("br"),o("span",{staticClass:"line-number"},[t._v("4")]),o("br"),o("span",{staticClass:"line-number"},[t._v("5")]),o("br"),o("span",{staticClass:"line-number"},[t._v("6")]),o("br"),o("span",{staticClass:"line-number"},[t._v("7")]),o("br"),o("span",{staticClass:"line-number"},[t._v("8")]),o("br"),o("span",{staticClass:"line-number"},[t._v("9")]),o("br"),o("span",{staticClass:"line-number"},[t._v("10")]),o("br"),o("span",{staticClass:"line-number"},[t._v("11")]),o("br")])]),o("p",[t._v("Эта структура помогает Gemini понять разные части вашего запроса и генерировать лучшие ответы[46].")]),t._v(" "),o("h3",{attrs:{id:"few-shot-prompting-обучение-на-примерах"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#few-shot-prompting-обучение-на-примерах"}},[t._v("#")]),t._v(" Few-Shot Prompting: Обучение на примерах")]),t._v(" "),o("p",[o("strong",[t._v("Few-shot prompting")]),t._v(" означает предоставление нескольких примеров желаемого поведения[23][46]. Вместо просто описания задачи, вы показываете примеры входа и желаемого выхода[23][46].")]),t._v(" "),o("p",[t._v("Например, если вы хотите, чтобы модель извлекала имена и возраст из текста, вы можете предоставить 2-3 примера, и модель выучит паттерн[23][46].")]),t._v(" "),o("h3",{attrs:{id:"управление-громкостью-выхода"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#управление-громкостью-выхода"}},[t._v("#")]),t._v(" Управление громкостью выхода")]),t._v(" "),o("p",[t._v("Gemini 3 по умолчанию предоставляет прямые и эффективные ответы[20][23]. Если вам нужны более разговорные или детальные ответы, вы должны явно это запросить в своих инструкциях[20][23].")]),t._v(" "),o("h3",{attrs:{id:"приоритизация-критических-инструкции"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#приоритизация-критических-инструкции"}},[t._v("#")]),t._v(" Приоритизация критических инструкций")]),t._v(" "),o("p",[o("strong",[t._v("Ранние инструкции имеют больший вес")]),t._v("[20][46]. Поместите наиболее важные ограничения, определение роли и требования к формату выхода в начало вашего промпта или в систему инструкций, а не в конец[20][46].")]),t._v(" "),o("h2",{attrs:{id:"ценообразование-и-планы-доступа"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#ценообразование-и-планы-доступа"}},[t._v("#")]),t._v(" Ценообразование и планы доступа")]),t._v(" "),o("p",[t._v("Google AI Studio имеет "),o("strong",[t._v("уникальную модель ценообразования")]),t._v(", которая различается в зависимости от того, включён ли вами Cloud Billing[14][32][36]:")]),t._v(" "),o("h3",{attrs:{id:"бесплатныи-план-без-биллинга"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#бесплатныи-план-без-биллинга"}},[t._v("#")]),t._v(" Бесплатный план (без биллинга)")]),t._v(" "),o("p",[t._v("Полностью "),o("strong",[t._v("бесплатный доступ")]),t._v(" к Google AI Studio и Gemini API, если вы не включаете Cloud Billing[14][36]. Однако существуют лимиты на использование:")]),t._v(" "),o("ul",[o("li",[t._v("Ежедневные лимиты на количество запросов")]),t._v(" "),o("li",[t._v("Лимиты на количество токенов в день")]),t._v(" "),o("li",[t._v("Доступ к моделям Flash и Flash-Lite бесплатно")])]),t._v(" "),o("p",[t._v("Важно отметить, что "),o("strong",[t._v("Google может использовать ваши данные для улучшения моделей")]),t._v(", если вы находитесь на бесплатном плане[32][36]. Это означает, что вы не должны отправлять конфиденциальную информацию без биллинга[32][36].")]),t._v(" "),o("h3",{attrs:{id:"платныи-план-с-cloud-billing"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#платныи-план-с-cloud-billing"}},[t._v("#")]),t._v(" Платный план (с Cloud Billing)")]),t._v(" "),o("p",[t._v("При включении Cloud Billing вы получаете доступ к "),o("strong",[t._v("pay-as-you-go ценообразованию")]),t._v(", основанному на использовании[14][32]:")]),t._v(" "),o("ul",[o("li",[o("strong",[t._v("Gemini 2.5 Pro")]),t._v(": $1.25 за миллион входных токенов, $10 за миллион выходных токенов (для промптов ≤ 200k токенов)")]),t._v(" "),o("li",[o("strong",[t._v("Gemini 2.5 Flash")]),t._v(": $0.30 за миллион входных токенов, $2.50 за миллион выходных токенов")]),t._v(" "),o("li",[o("strong",[t._v("Gemini 2.5 Flash-Lite")]),t._v(": $0.075 за миллион входных токенов, $0.30 за миллион выходных токенов")]),t._v(" "),o("li",[o("strong",[t._v("Gemini 3 Pro")]),t._v(": $1.25 за миллион входных токенов, $10 за миллион выходных токенов (для промптов ≤ 200k токенов)")]),t._v(" "),o("li",[o("strong",[t._v("Image Generation (Imagen 3)")]),t._v(": $0.039 за изображение")]),t._v(" "),o("li",[o("strong",[t._v("Video Generation (Veo 3.1)")]),t._v(": $0.40 за стандартное видео, $0.15 за быстрое видео")])]),t._v(" "),o("p",[t._v("Важно: "),o("strong",[t._v("при включении биллинга Google гарантирует, что ваши данные не будут использованы для обучения")]),t._v(" её моделей[32][36].")]),t._v(" "),o("h3",{attrs:{id:"google-ai-pro-и-ultra-подписки"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#google-ai-pro-и-ultra-подписки"}},[t._v("#")]),t._v(" Google AI Pro и Ultra подписки")]),t._v(" "),o("p",[t._v("Для потребительского использования доступны "),o("strong",[t._v("Google AI Pro ($20/месяц)")]),t._v(" и "),o("strong",[t._v("Google AI Ultra ($30-35/месяц)")]),t._v(", которые предоставляют более высокие лимиты на использование моделей[11][36]:")]),t._v(" "),o("ul",[o("li",[o("strong",[t._v("Pro")]),t._v(": 1,000 месячных AI кредитов (используется для всех функций, включая Flow, Whisk и видео генерацию)")]),t._v(" "),o("li",[o("strong",[t._v("Ultra")]),t._v(": 25,000 месячных AI кредитов")])]),t._v(" "),o("h2",{attrs:{id:"безопасность-приватность-и-фильтры-контента"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#безопасность-приватность-и-фильтры-контента"}},[t._v("#")]),t._v(" Безопасность, приватность и фильтры контента")]),t._v(" "),o("p",[t._v("Google AI Studio включает встроенные "),o("strong",[t._v("системы безопасности и фильтрации контента")]),t._v(" для предотвращения генерирования вредоносного контента[59][62]:")]),t._v(" "),o("h3",{attrs:{id:"настраиваемые-фильтры-содержания"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#настраиваемые-фильтры-содержания"}},[t._v("#")]),t._v(" Настраиваемые фильтры содержания")]),t._v(" "),o("p",[t._v("Google предоставляет пять основных категорий фильтров, которые вы можете настраивать[59][62]:")]),t._v(" "),o("ol",[o("li",[o("strong",[t._v("Harassment (Преследование)")]),t._v(": негативные или вредные комментарии, направленные на личность")]),t._v(" "),o("li",[o("strong",[t._v("Hate speech (Ненавистнические высказывания)")]),t._v(": грубой, неуважительный или оскорбительный контент")]),t._v(" "),o("li",[o("strong",[t._v("Sexually explicit (Сексуально откровенный)")]),t._v(": ссылки на сексуальные акты")]),t._v(" "),o("li",[o("strong",[t._v("Dangerous content (Опасный контент)")]),t._v(": содержание, поощряющее вредные действия")]),t._v(" "),o("li",[o("strong",[t._v("Civic integrity (Гражданская целостность)")]),t._v(": запросы, связанные с выборами")])]),t._v(" "),o("p",[t._v("Для каждой категории вы можете установить пороговое значение: "),o("strong",[t._v("Block none")]),t._v(" (показать всё), "),o("strong",[t._v("Block only high")]),t._v(" (блокировать только высокую вероятность), "),o("strong",[t._v("Block medium and above")]),t._v(" (блокировать среднюю вероятность и выше), "),o("strong",[t._v("Block low and above")]),t._v(" (блокировать всё) или "),o("strong",[t._v("Off")]),t._v(" (отключить фильтр)[59][62].")]),t._v(" "),o("h3",{attrs:{id:"встроенные-защиты"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#встроенные-защиты"}},[t._v("#")]),t._v(" Встроенные защиты")]),t._v(" "),o("p",[t._v("Некоторые типы контента всегда блокируются и не могут быть отключены, включая "),o("strong",[t._v("контент, связанный с безопасностью детей")]),t._v("[59][62]. Это фундаментальное ограничение, которое Google не позволяет обойти[59][62].")]),t._v(" "),o("h3",{attrs:{id:"data-usage-и-privacy"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#data-usage-и-privacy"}},[t._v("#")]),t._v(" Data Usage и Privacy")]),t._v(" "),o("p",[t._v("На бесплатном плане Google может использовать ваши промпты, загруженные файлы и генерируемый контент для улучшения её моделей и служб[32][35][36]. Это означает, что "),o("strong",[t._v("людьми могут просматривать ваши данные после отключения от вашей учётной записи")]),t._v("[32][35][36].")]),t._v(" "),o("p",[t._v("При включении Cloud Billing ваши данные "),o("strong",[t._v("классифицируются как платная служба")]),t._v(", и Google обещает не использовать их для обучения и развития моделей[32][36]. Данные обрабатываются в соответствии с Google Data Processing Addendum и Data Retention Policy[35][36].")]),t._v(" "),o("h2",{attrs:{id:"сравнение-с-другими-платформами-и-инструментами"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#сравнение-с-другими-платформами-и-инструментами"}},[t._v("#")]),t._v(" Сравнение с другими платформами и инструментами")]),t._v(" "),o("p",[t._v("На ноябрь 2025 года Google AI Studio конкурирует с несколькими другими платформами[34][41][48][51]:")]),t._v(" "),o("p",[o("strong",[t._v("vs. ChatGPT / OpenAI")]),t._v(": ChatGPT остаётся более популярным среди широкой публики благодаря своему долгому присутствию на рынке и сильной маркетинговой кампании[51]. Однако Google AI Studio часто превосходит ChatGPT в мультимодальных возможностях, особенно в генерировании видео (Veo 3.1), и предлагает более генеральный доступ к мощным инструментам разработчика[34][41][51].")]),t._v(" "),o("p",[o("strong",[t._v("vs. Claude / Anthropic")]),t._v(": Claude известна высокой безопасностью и этичным подходом[51]. Для профессионального кодирования Claude часто считается лучше, чем Gemini[51]. Однако Google AI Studio предлагает более широкий спектр инструментов, включая видео и изображение генерацию[34][41][51].")]),t._v(" "),o("p",[o("strong",[t._v("vs. Vertex AI")]),t._v(": Vertex AI — это корпоративная версия Google AI Studio с дополнительными функциями для масштабирования, мониторинга и управления[58][61]. Google AI Studio — это упрощённая, бесплатная версия для прототипирования[58][61].")]),t._v(" "),o("p",[o("strong",[t._v("Основное преимущество Google AI Studio")]),t._v(": "),o("strong",[t._v("полностью бесплатный доступ к мощным инструментам")]),t._v(", включая видео генерацию, которая обычно дорогая на других платформах[34][41].")]),t._v(" "),o("h2",{attrs:{id:"развертывание-и-интеграция-от-прототипа-к-продакшену"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#развертывание-и-интеграция-от-прототипа-к-продакшену"}},[t._v("#")]),t._v(" Развертывание и интеграция: От прототипа к продакшену")]),t._v(" "),o("h3",{attrs:{id:"одна-кнопка-развертывания-в-cloud-run"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#одна-кнопка-развертывания-в-cloud-run"}},[t._v("#")]),t._v(" Одна кнопка развертывания в Cloud Run")]),t._v(" "),o("p",[t._v("Одной из самых мощных функций Google AI Studio является "),o("strong",[t._v("развертывание приложения в Cloud Run одним нажатием кнопки")]),t._v('[30][43]. Когда вы создали приложение в AI Studio, вы можете нажать "Deploy to Cloud Run" и система:')]),t._v(" "),o("ol",[o("li",[t._v("Генерирует Docker контейнер с вашим приложением")]),t._v(" "),o("li",[t._v("Развёртывает его в Google Cloud Run")]),t._v(" "),o("li",[t._v("Предоставляет вам стабильный HTTPS URL")]),t._v(" "),o("li",[t._v("Отправляет API ключ на сервер (так он остаётся защищённым)")]),t._v(" "),o("li",[t._v("Создаёт автоматическое масштабирование")])]),t._v(" "),o("p",[t._v("Всё это происходит практически мгновенно, превращая ваш прототип в живое приложение[30][43].")]),t._v(" "),o("h3",{attrs:{id:"cloud-run-mcp-server"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#cloud-run-mcp-server"}},[t._v("#")]),t._v(" Cloud Run MCP Server")]),t._v(" "),o("p",[t._v("Для разработчиков, использующих "),o("strong",[t._v("Model Context Protocol (MCP)")]),t._v(" совместимые инструменты вроде Claude, Google недавно представила "),o("strong",[t._v("Cloud Run MCP Server")]),t._v("[30]. Это позволяет AI агентам (например, в Claude или других инструментах) развёртывать приложения в Cloud Run через MCP[30].")]),t._v(" "),o("h2",{attrs:{id:"реальные-примеры-использования"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#реальные-примеры-использования"}},[t._v("#")]),t._v(" Реальные примеры использования")]),t._v(" "),o("p",[t._v("Google AI Studio используется для различных целей[13][21][24][48]:")]),t._v(" "),o("p",[o("strong",[t._v("Генерирование видео контента")]),t._v(": компании используют Veo 3.1 для создания демонстрационных видеосправок для клиентов, рекламных материалов и социальных медиа контента[9][57].")]),t._v(" "),o("p",[o("strong",[t._v("Анализ документов")]),t._v(": организации загружают PDF-файлы, контракты и другие документы и используют Gemini для анализа, суммирования и извлечения информации[13][21].")]),t._v(" "),o("p",[o("strong",[t._v("Создание приложений без кода")]),t._v(': с помощью функции "vibe coding" люди без опыта программирования могут описать приложение, которое они хотят, и Gemini генерирует полнофункциональное веб-приложение[13][24][30].')]),t._v(" "),o("p",[o("strong",[t._v("Кодирование агентов")]),t._v(": разработчики используют Google AI Studio для создания автономных агентов, которые выполняют сложные многошаговые задачи, вроде автоматизации тестирования или управления инфраструктурой[31][43].")]),t._v(" "),o("p",[o("strong",[t._v("Живой анализ экрана")]),t._v(": преподаватели и тренеры используют прямую трансляцию с экрана для получения мгновенных объяснений и обратной связи от AI[5][25].")]),t._v(" "),o("h2",{attrs:{id:"google-antigravity-будущее-развития-ai-studio"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#google-antigravity-будущее-развития-ai-studio"}},[t._v("#")]),t._v(" Google Antigravity: Будущее развития AI Studio")]),t._v(" "),o("p",[t._v("В ноябре 2025 года Google представила "),o("strong",[t._v("Google Antigravity")]),t._v(" — новую агентивную платформу разработки, которая переосмысляет взаимодействие разработчиков с AI[7][40][43]. Antigravity использует Gemini 3 для полностью автономного выполнения задач разработки, от планирования до кодирования, тестирования и развертывания[7][40].")]),t._v(" "),o("p",[t._v("Antigravity представляет собой эволюцию AI Studio, где вместо того, чтобы разработчик вручную взаимодействовать с моделью, модель действует как активный партнер, который может:")]),t._v(" "),o("ul",[o("li",[t._v("Получить GitHub issue или описание задачи")]),t._v(" "),o("li",[t._v("Спланировать необходимые изменения")]),t._v(" "),o("li",[t._v("Реализовать код")]),t._v(" "),o("li",[t._v("Запустить тесты")]),t._v(" "),o("li",[t._v("Отладить проблемы")]),t._v(" "),o("li",[t._v("Создать pull request для пересмотра")])]),t._v(" "),o("p",[t._v("Всё это происходит автономно, пока разработчик может работать над чем-то другим[7][40][43].")]),t._v(" "),o("h2",{attrs:{id:"лучшие-практики-и-советы-по-оптимизации"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#лучшие-практики-и-советы-по-оптимизации"}},[t._v("#")]),t._v(" Лучшие практики и советы по оптимизации")]),t._v(" "),o("p",[t._v("Для максимизации использования Google AI Studio:")]),t._v(" "),o("ol",[o("li",[o("p",[o("strong",[t._v("Начните с Chat для экспериментирования")]),t._v(": используйте Chat Prompts для изучения возможностей моделей перед созданием сложных приложений[2][16].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Используйте примеры (Few-shot)")]),t._v(": предоставьте примеры входа и выхода для лучших результатов[23][46].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Структурируйте сложные промпты")]),t._v(": используйте XML теги для разделения различных частей вашего запроса[20][46].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Включите Grounding для точности")]),t._v(": при нужде в точной, проверяемой информации используйте Google Search или другие источники grounding[19][59].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Тестируйте различные модели")]),t._v(": не все модели одинаково хороши для всех задач; Gemini 3 лучше для рассуждения, а Gemini 2.5 Flash лучше для скорости[52][53].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Управляйте фильтрами безопасности")]),t._v(": если вы создаёте приложение, требующее более нестрогих фильтров, отрегулируйте их в соответствии с вашим use case[59][62].")])]),t._v(" "),o("li",[o("p",[o("strong",[t._v("Не отправляйте конфиденциальные данные на бесплатном плане")]),t._v(": включите Cloud Billing, если вы работаете с чувствительной информацией[32][36].")])])]),t._v(" "),o("h2",{attrs:{id:"ограничения-и-честная-оценка"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#ограничения-и-честная-оценка"}},[t._v("#")]),t._v(" Ограничения и честная оценка")]),t._v(" "),o("p",[t._v("Несмотря на мощь Google AI Studio, существуют некоторые ограничения, которые следует учитывать[39][51]:")]),t._v(" "),o("p",[o("strong",[t._v("Надежность")]),t._v(': недавно были сообщения о проблемах с надежностью Gemini API, особенно во время пиковых часов ("Transatlantic Timeout")[39]. Google улучшает это, но на практике вы иногда можете испытывать перебои в обслуживании[39].')]),t._v(" "),o("p",[o("strong",[t._v("Недостаток в некоторых областях")]),t._v(": на некоторых специализированных бенчмарках, вроде чистого кодирования, Claude иногда превосходит Gemini[51].")]),t._v(" "),o("p",[o("strong",[t._v("Географические ограничения")]),t._v(": Google AI Studio недоступна в некоторых странах (например, в некоторых частях ЕС) из-за нормативных ограничений[33].")]),t._v(" "),o("p",[o("strong",[t._v("Не заменяет полный IDE")]),t._v(": хотя Google AI Studio отлична для прототипирования, полнофункциональная разработка всё ещё может требовать VS Code, IntelliJ и других инструментов[34][41].")]),t._v(" "),o("h2",{attrs:{id:"заключение-google-ai-studio-как-ворота-к-ai-разработке"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#заключение-google-ai-studio-как-ворота-к-ai-разработке"}},[t._v("#")]),t._v(" Заключение: Google AI Studio как ворота к AI разработке")]),t._v(" "),o("p",[t._v("Google AI Studio на ноябрь 2025 года представляет собой "),o("strong",[t._v("наиболее доступный и мощный бесплатный инструмент для работы с передовыми AI моделями")]),t._v("[1][10][34][41]. С бесплатным доступом к Gemini 3 и другим моделям, поддержкой мультимодальных входов, включением функционального вызова, grounding, выполнения кода и развёртывания облако, Google AI Studio предоставляет всё, что нужно как новичкам, так и опытным разработчикам.")]),t._v(" "),o("p",[t._v("Платформа особенно сияет в её простоте, универсальности и интеграции с Google Cloud. Для тех, кто хочет экспериментировать с AI, создавать приложения без кода, или интегрировать AI в существующие рабочие процессы, Google AI Studio — это отличная отправная точка, которая может вырасти с вашими потребностями вплоть до масштабных корпоративных развёртываний через Vertex AI и Antigravity.")]),t._v(" "),o("p",[t._v("Если вы ещё не исследовали Google AI Studio, сейчас идеальное время начать — платформа полностью бесплатна, не требует сложной конфигурации и может буквально занять минуты до вашего первого запущенного приложения AI.")]),t._v(" "),o("h2",{attrs:{id:"источники-инфы"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#источники-инфы"}},[t._v("#")]),t._v(" Источники инфы")]),t._v(" "),o("p",[t._v("[1] https://ai.google.dev/aistudio\n[2] https://ai.google.dev/gemini-api/docs/ai-studio-quickstart\n[3] https://en.wikipedia.org/wiki/Google_AI_Studio\n[4] https://aistudio.google.com\n[5] https://www.youtube.com/watch?v=IHOJUJjZbzc\n[6] https://ai.google\n[7] https://blog.google/products/gemini/gemini-3/\n[8] https://ai.google.dev/gemini-api/docs/pricing\n[9] https://gemini.google/overview/video-generation/\n[10] https://aistudio.google.com\n[11] https://one.google.com/intl/en/about/google-ai-plans/\n[12] https://aistudio.google.com/models/veo-3\n[13] https://www.youtube.com/watch?v=-aT3Uh1hyis\n[14] https://www.datastudios.org/post/google-ai-studio-free-plans-trials-and-subscriptions-access-tiers-limits-and-upgrade-paths\n[15] https://cloud.google.com/use-cases/ai-code-generation\n[16] https://ai.google.dev/gemini-api/docs/ai-studio-quickstart\n[17] https://ai.google.dev/gemini-api/docs/pricing\n[18] https://aistudio.google.com/live\n[19] https://docs.cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview\n[20] https://ai.google.dev/gemini-api/docs/prompting-strategies\n[21] https://cloud.google.com/blog/products/ai-machine-learning/real-world-gen-ai-use-cases-with-technical-blueprints\n[22] https://ai.google.dev/gemini-api/docs/function-calling\n[23] https://docs.cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/few-shot-examples\n[24] https://www.youtube.com/watch?v=dyU6mW24tIQ\n[25] https://discuss.ai.google.dev/t/how-to-use-screen-sharing-mode-in-https-aistudio-google-com-live/85970\n[26] https://ai.google.dev/gemini-api/docs/gemini-3\n[27] https://ai.google.dev/gemma/docs/core/deploy_to_cloud_run_from_ai_studio\n[28] https://aistudio.google.com/live\n[29] https://supergok.com/gemini-3-google-ai-model/\n[30] https://cloud.google.com/blog/products/ai-machine-learning/ai-studio-to-cloud-run-and-cloud-run-mcp-server\n[31] https://technologymagazine.com/news/how-will-google-gemini-3-deliver-on-agentic-ai-promise\n[32] https://cybernews.com/ai-tools/google-ai-studio-review/\n[33] https://ai.google.dev/gemini-api/docs/available-regions\n[34] https://mkaplan.substack.com/p/googles-ai-powerhouses-ai-studio\n[35] https://ai.google.dev/gemini-api/docs/usage-policies\n[36] https://cloud.google.com/blog/products/ai-machine-learning/ai-studio-to-cloud-run-and-cloud-run-mcp-server\n[37] https://cloud.google.com/ai/gemini\n[38] https://www.deeplearning.ai/the-batch/google-introduces-gemini-2-0-flash-a-faster-more-capable-ai-model/\n[39] https://martinalderson.com/posts/google-ai-studio-api-unreliable-for-two-weeks/\n[40] https://blog.google/products/gemini/gemini-3/\n[41] https://visionvix.com/google-ai-studio-vs-gemini-comparison/\n[42] https://u.osu.edu/bhatnagar/?app=google-ai-studio-status\n[43] https://cloud.google.com/blog/products/ai-machine-learning/gemini-3-is-available-for-enterprise\n[44] https://www.vice.com/en/article/google-five-updates-gemini-live-november-2025/\n[45] https://fortune.com/2025/11/19/google-gemini-3-antigravity-ai-explained/\n[46] https://docs.cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/structure-prompts\n[47] https://ai.google.dev/gemini-api/docs/batch-api\n[48] https://zapier.com/blog/chatgpt-alternatives/\n[49] https://ai.google.dev/gemini-api/docs/ai-studio-quickstart\n[50] https://ai.google.dev/api/batch-api\n[51] https://creatoreconomy.so/p/chatgpt-vs-claude-vs-gemini-the-best-ai-model-for-each-use-case-2025\n[52] https://ai.google.dev/gemini-api/docs/gemini-3\n[53] https://ai.google.dev/gemini-api/docs/models\n[54] https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/audio-understanding\n[55] https://aistudio.google.com\n[56] https://deepmind.google/models/gemini/flash/\n[57] https://aistudio.google.com/models/veo-3\n[58] https://cloud.google.com/generative-ai-studio\n[59] https://ai.google.dev/gemini-api/docs/safety-settings\n[60] https://www.youtube.com/watch?v=a8NtWQbQI4E\n[61] https://cloud.google.com/ai/gemini\n[62] https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters\n[63] https://ai.google.dev/gemini-api/docs/ai-studio-quickstart")]),t._v(" "),o("h2",{attrs:{id:"уровень"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#уровень"}},[t._v("#")]),t._v(" Уровень")]),t._v(" "),o("p",[t._v("1-2")]),t._v(" "),o("h2",{attrs:{id:"примеры-из-жизни"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#примеры-из-жизни"}},[t._v("#")]),t._v(" Примеры из жизни")]),t._v(" "),o("ul",[o("li",[t._v("Создание контента для соцсетей")]),t._v(" "),o("li",[t._v("Генерация изображений для статей")]),t._v(" "),o("li",[t._v("Создание видео-контента")]),t._v(" "),o("li",[t._v("Озвучка текстов")])]),t._v(" "),o("h2",{attrs:{id:"полезные-ссылки"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#полезные-ссылки"}},[t._v("#")]),t._v(" Полезные ссылки")]),t._v(" "),o("ul",[o("li",[o("a",{attrs:{href:"https://aistudio.google.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("Google AI Studio"),o("OutboundLink")],1)]),t._v(" "),o("li",[o("a",{attrs:{href:"https://ai.google.dev",target:"_blank",rel:"noopener noreferrer"}},[t._v("Документация Gemini"),o("OutboundLink")],1)])]),t._v(" "),o("h2",{attrs:{id:"заметки"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#заметки"}},[t._v("#")]),t._v(" Заметки")])])}),[],!1,null,null,null);o.default=a.exports}}]);