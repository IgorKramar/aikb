(window.webpackJsonp=window.webpackJsonp||[]).push([[61],{383:function(t,a,e){"use strict";e.r(a);var _=e(18),r=Object(_.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"температура-и-другие-параметры-модели"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#температура-и-другие-параметры-модели"}},[t._v("#")]),t._v(" Температура и другие параметры модели")]),t._v(" "),a("p",[t._v("При работе с API моделей (не в обычном чате, а при программировании) можно настраивать параметры, которые влияют на то, как модель генерирует ответы.")]),t._v(" "),a("h2",{attrs:{id:"температура-temperature"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#температура-temperature"}},[t._v("#")]),t._v(" Температура (Temperature)")]),t._v(" "),a("p",[a("strong",[t._v("Температура")]),t._v(" — это параметр, который контролирует «креативность» или «случайность» ответов модели.")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Низкая температура (0.1-0.3)")]),t._v(": модель даёт более предсказуемые, точные ответы. Хорошо для фактов, технических задач, переводов")]),t._v(" "),a("li",[a("strong",[t._v("Средняя температура (0.7-0.9)")]),t._v(": баланс между точностью и креативностью. Хорошо для большинства задач")]),t._v(" "),a("li",[a("strong",[t._v("Высокая температура (1.0-2.0)")]),t._v(": модель более креативна, но может быть менее точной. Хорошо для творческих задач, генерации идей")])]),t._v(" "),a("h3",{attrs:{id:"примеры"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#примеры"}},[t._v("#")]),t._v(" Примеры:")]),t._v(" "),a("p",[t._v("Температура 0.2 (низкая):")]),t._v(" "),a("ul",[a("li",[t._v("Вопрос: «Столица Франции?»")]),t._v(" "),a("li",[t._v("Ответ: «Париж» (всегда одинаково)")])]),t._v(" "),a("p",[t._v("Температура 1.5 (высокая):")]),t._v(" "),a("ul",[a("li",[t._v("Вопрос: «Напиши стихотворение про кота»")]),t._v(" "),a("li",[t._v("Ответ: каждый раз разное, более креативное стихотворение")])]),t._v(" "),a("h2",{attrs:{id:"top-p-nucleus-sampling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#top-p-nucleus-sampling"}},[t._v("#")]),t._v(" Top-p (Nucleus Sampling)")]),t._v(" "),a("p",[a("strong",[t._v("Top-p")]),t._v(" — параметр, который ограничивает, из каких слов модель может выбирать следующее слово.")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Низкий top-p (0.1-0.5)")]),t._v(": модель выбирает только из самых вероятных слов — более предсказуемо")]),t._v(" "),a("li",[a("strong",[t._v("Высокий top-p (0.9-1.0)")]),t._v(": модель может выбирать из большего набора слов — более разнообразно")])]),t._v(" "),a("p",[t._v("Обычно используется вместе с температурой.")]),t._v(" "),a("h2",{attrs:{id:"max-tokens"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#max-tokens"}},[t._v("#")]),t._v(" Max tokens")]),t._v(" "),a("p",[a("strong",[t._v("Max tokens")]),t._v(" — максимальное количество токенов в ответе модели. Ограничивает длину ответа.")]),t._v(" "),a("ul",[a("li",[t._v("Если установить max_tokens=100, модель остановится после ~100 токенов")]),t._v(" "),a("li",[t._v("Полезно, когда нужен короткий ответ")])]),t._v(" "),a("h2",{attrs:{id:"frequency-penalty-и-presence-penalty"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#frequency-penalty-и-presence-penalty"}},[t._v("#")]),t._v(" Frequency penalty и Presence penalty")]),t._v(" "),a("p",[t._v("Эти параметры помогают избежать повторений:")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Frequency penalty")]),t._v(": наказывает за частое повторение одних и тех же слов")]),t._v(" "),a("li",[a("strong",[t._v("Presence penalty")]),t._v(": поощряет использование новых тем и слов")])]),t._v(" "),a("p",[t._v("Полезно для длинных текстов, чтобы избежать зацикливания.")]),t._v(" "),a("h2",{attrs:{id:"практические-рекомендации"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#практические-рекомендации"}},[t._v("#")]),t._v(" Практические рекомендации")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Для фактов и точных ответов")]),t._v(": temperature=0.2, top_p=0.1")]),t._v(" "),a("li",[a("strong",[t._v("Для обычных задач")]),t._v(": temperature=0.7, top_p=0.9 (значения по умолчанию)")]),t._v(" "),a("li",[a("strong",[t._v("Для творческих задач")]),t._v(": temperature=1.2, top_p=0.95")]),t._v(" "),a("li",[a("strong",[t._v("Для кода")]),t._v(": temperature=0.1-0.3 (нужна точность)")])]),t._v(" "),a("h2",{attrs:{id:"уровень"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#уровень"}},[t._v("#")]),t._v(" Уровень")]),t._v(" "),a("p",[t._v("2")]),t._v(" "),a("h2",{attrs:{id:"примеры-из-жизни"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#примеры-из-жизни"}},[t._v("#")]),t._v(" Примеры из жизни")]),t._v(" "),a("ul",[a("li",[t._v("Настройка температуры для генерации идей")]),t._v(" "),a("li",[t._v("Ограничение длины ответа через max_tokens")]),t._v(" "),a("li",[t._v("Использование penalty для избежания повторений в длинных текстах")])]),t._v(" "),a("h2",{attrs:{id:"полезные-ссылки-для-этого-уровня"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#полезные-ссылки-для-этого-уровня"}},[t._v("#")]),t._v(" Полезные ссылки для этого уровня")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://platform.openai.com/docs/api-reference/chat/create",target:"_blank",rel:"noopener noreferrer"}},[t._v("Документация OpenAI API параметров"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B0"}},[t._v("Гайд по настройке параметров")])])]),t._v(" "),a("h2",{attrs:{id:"заметки"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#заметки"}},[t._v("#")]),t._v(" Заметки")])])}),[],!1,null,null,null);a.default=r.exports}}]);