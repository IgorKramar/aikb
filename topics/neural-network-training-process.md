# Как обучается нейросеть: процесс обучения

Обучение нейросети — это процесс, когда она смотрит на примеры, делает ошибки, понимает их и постепенно становится лучше.

## Два этапа работы нейросети

### 1. Прямое распространение (Forward Propagation)

Это когда данные проходят через нейросеть от входа к выходу:

1. Данные попадают на входной слой
2. Проходят через скрытые слои
3. Достигают выходного слоя
4. Нейросеть выдаёт ответ

**Простая аналогия**: как вода течёт по трубам от начала до конца.

### 2. Обратное распространение ошибки (Backpropagation)

Это когда нейросеть понимает свои ошибки и исправляет их:

1. Сравнивает свой ответ с правильным
2. Вычисляет, насколько ошиблась
3. "Идёт назад" по слоям, понимая, где именно ошибка
4. Корректирует веса и смещения, чтобы в следующий раз ошибиться меньше

**Простая аналогия**: как ученик, получив двойку, разбирает, где именно ошибся, и исправляет подход.

## Процесс обучения пошагово

### Шаг 1: Инициализация

В начале обучения веса и смещения задаются **случайными** значениями.

Почему случайными? Потому что мы не знаем заранее, какие веса будут правильными. Нейросеть сама найдёт их в процессе обучения.

### Шаг 2: Прямое распространение

Берётся один пример из обучающих данных (например, картинка с цифрой "5"):

1. Картинка преобразуется в числа (яркость пикселей)
2. Эти числа подаются на входной слой
3. Данные проходят через все слои
4. Выходной слой выдаёт ответ (например, "это цифра 3" — неправильно!)

### Шаг 3: Вычисление ошибки

Сравниваем ответ нейросети с правильным ответом:

- Правильный ответ: "5"
- Ответ нейросети: "3"
- Ошибка: нейросеть неправильно распознала цифру

Ошибка вычисляется математически — чем больше разница, тем больше ошибка.

### Шаг 4: Обратное распространение

Ошибка "распространяется" назад по слоям:

1. **Выходной слой**: вычисляется, насколько каждый нейрон ошибся
2. **Скрытые слои**: вычисляется, какой вклад каждый нейрон внёс в ошибку
3. **Входной слой**: здесь ошибки не вычисляются (это просто входные данные)

**Простая аналогия**: как найти виноватого в цепочке:
- Выходной слой: "Я выдал неправильный ответ"
- Скрытые слои: "Я передал неправильную информацию"
- Каждый слой понимает свой вклад в ошибку

### Шаг 5: Обновление весов

На основе ошибки корректируются веса и смещения:

- Если нейрон "переоценил" важность входа — вес уменьшается
- Если нейрон "недооценил" важность входа — вес увеличивается
- Смещения тоже корректируются

**Темп обучения** определяет, насколько сильно меняются веса:
- Слишком большой: нейросеть "перепрыгивает" правильное решение
- Слишком маленький: обучение идёт очень медленно
- Правильный: постепенное улучшение

### Шаг 6: Повторение

Процесс повторяется для всех примеров в обучающем наборе.

## Эпохи обучения

**Эпоха** — это один полный проход по всем обучающим примерам.

Обычно нейросеть обучается много эпох:
- Первая эпоха: много ошибок, случайные ответы
- Десятая эпоха: меньше ошибок, начинает понимать закономерности
- Сотня эпох: хорошо распознаёт большинство примеров
- Тысяча эпох: отличные результаты (но может быть переобучение)

## Пакеты (Batches)

Обычно примеры обрабатываются не по одному, а **пакетами** (batches):

- Пакет из 125 примеров
- Нейросеть обрабатывает все 125 примеров
- Вычисляет среднюю ошибку
- Обновляет веса на основе средней ошибки
- Переходит к следующему пакету

**Зачем пакеты?**
- Быстрее обучение
- Более стабильное обновление весов
- Эффективное использование ресурсов

## Простая аналогия: обучение вождению

1. **Инициализация**: новичок садится за руль (случайные навыки)
2. **Прямое распространение**: пытается проехать (делает ошибки)
3. **Вычисление ошибки**: инструктор говорит, что не так
4. **Обратное распространение**: новичок понимает, где именно ошибся
5. **Обновление весов**: корректирует действия (меньше давить на газ, больше смотреть в зеркало)
6. **Повторение**: снова пытается проехать, но уже лучше
7. **Много эпох**: после сотен попыток становится хорошим водителем

## Важные моменты

- **Обучение занимает время**: чем сложнее задача, тем дольше учится
- **Нужно много примеров**: чем больше данных, тем лучше результат
- **Важен баланс**: слишком долгое обучение может привести к "заучиванию" (переобучению)
- **Тестирование**: после обучения проверяют на новых примерах, которые нейросеть не видела

## Уровень
1

## Примеры из жизни
- Обучение распознаванию рукописных цифр
- Обучение распознаванию лиц
- Обучение переводу текста
- Обучение рекомендательным системам

## Полезные ссылки для этого уровня
- [Визуализация обратного распространения](ссылка)
- [Интерактивные примеры обучения](ссылка)

## Заметки
