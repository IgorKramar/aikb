# Что такое токены и контекстное окно

## Токены

**Токен** — это единица текста, которую понимает модель. Это не всегда одно слово.

Например, фраза "привет, как дела?" может быть разбита на токены так:
- "привет" — 1 токен
- "," — 1 токен
- " как" — 1 токен
- " дела" — 1 токен
- "?" — 1 токен

Итого: 5 токенов для короткой фразы.

В среднем:
- 1 токен ≈ 0.75 слова на русском
- 1 токен ≈ 4 символа

## Контекстное окно

**Контекстное окно** (context window) — это максимальное количество токенов, которое модель может «помнить» в одном разговоре. Это включает и твои сообщения, и ответы модели.

### Примеры размеров контекстного окна:

- **GPT-3.5**: ~4,000 токенов (примерно 3,000 слов)
- **GPT-4**: ~8,000 токенов (примерно 6,000 слов), в расширенной версии до 128,000
- **Claude 3**: до 200,000 токенов (примерно 150,000 слов)

## Почему это важно?

1. **Ограничение длины разговора**: если контекстное окно заполнено, модель «забывает» начало разговора
2. **Стоимость**: обычно платят за количество токенов — чем больше, тем дороже
3. **Качество ответов**: модель лучше работает, когда у неё есть весь нужный контекст

## Как считать токены?

Можно использовать онлайн-счётчики или API:
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer) — показывает, как текст разбивается на токены
- В API OpenAI есть функция для подсчёта токенов

## Практические советы

- **Короткие промпты** экономят токены и деньги
- **Важную информацию** лучше давать в начале разговора
- **Длинные документы** можно разбивать на части
- **Старые сообщения** автоматически «забываются», когда контекстное окно переполняется

## Уровень
2

## Примеры из жизни
- Короткий вопрос: ~10-20 токенов
- Средний промпт: ~100-200 токенов
- Длинный документ для анализа: ~1000-5000 токенов
- Полный разговор: может достигать лимита контекстного окна

## Полезные ссылки для этого уровня
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)
- [Документация по токенам OpenAI](https://platform.openai.com/docs/guides/text-generation)

## Заметки
