# Нейросети для художников: Полный практический курс 2025-2026

## Введение: Новая эпоха в искусстве

Мы стоим на пороге самого глубокого переворота в визуальном искусстве за последние 500 лет. Со времён изобретения фотографии ничто так не изменило природу творчества, как появление генеративного ИИ.[1][2]

Однако это не конец искусства, как пугают алармисты. Наоборот, это открытие **новых инструментов** — как когда-то появились краски в тюбиках, позволив импрессионистам выйти из студий, или как Photoshop революционизировал дизайн.

**Ключевой момент**: нейросети — это не замена художнику. Это **расширение его возможностей**, способ работать быстрее, экспериментировать смелее и воплощать идеи, которые раньше были невозможны.

Эта лекция предназначена для художников, дизайнеров и творцов, которые хотят не просто использовать ИИ, но **контролировать его**, направлять его творчество и интегрировать нейросети в свой уникальный процесс.

***

## Модуль 1: Философия и концептуальные основы

### 1.1 ИИ не заменит художника, но художник, использующий ИИ, может заменить художника, который ИИ не использует

Это не шутка — это суровая реальность 2025 года. Понимание этого психологически важно. ИИ — это не враг творчества, это **инструмент, как кисть или графический планшет**.

Но почему некоторые художники так боятся?

**Три психологических барьера:**

1. **Миф об "авторстве"** — художнику кажется, что если машина создала изображение, то авторство меньше. Это неверно. Художник, который умело направляет ИИ, является **автором** так же, как режиссер — автор фильма, хотя он не сам снимает, не сам монтирует.

2. **Страх безработицы** — "Если есть ИИ, мне больше не нужны художники". На самом деле спрос на качественный визуальный контент в 2025 году выше, чем когда-либо. Просто меняется форма работы.

3. **"Это не настоящее искусство"** — философская позиция. Но история искусства учит, что каждый новый инструмент изначально встречал сопротивление. Фотографию называли "смертью живописи". Потом фотография породила новые формы искусства.

### 1.2 Творческий процесс с ИИ: новая парадигма

Традиционный процесс художника:

```
Идея → Скетч → Доработка → Правки → Финал
(часов работы)
```

Процесс с ИИ:

```
Идея → Быстрая визуализация → Быстрые эксперименты → Выбор направления →
Доработка в фотошопе/коде → Финал
(минут вместо часов)
```

**Результат**: художник может обработать в 10 раз больше идей, быстрее найти лучшее решение, экспериментировать смелее.

### 1.3 Расширенное определение художника 2025-2026

**Художник** — это больше не только человек, который может рисовать рукой. Это человек, который:

- Понимает **композицию, цвет, анатомию**
- Может **сформулировать идею** словами
- Умеет **критически оценивать** результат
- Может **редактировать и комбинировать** элементы
- Знает **историю искусства и стили**
- Может **контролировать ИИ** через правильные промпты

Иными словами, художник 2025-го года — это **режиссер своего творчества**, а не просто исполнитель.

***

## Модуль 2: Ландшафт инструментов (2025-2026)

### 2.1 Главные игроки и их характеристики

На рынке генеративного ИИ произошла консолидация. Вместо десятков инструментов, остались несколько лидеров, каждый с уникальным профилем:[2][3][4][5]

#### DALL-E 3 (OpenAI)

**Сильные стороны:**
- **Точность понимания текста** — DALL-E 3 лучше всех понимает текстовые описания и воплощает их буквально
- **Хороший текст на картинках** — в отличие от других генераторов, может писать правильно и читаемо
- **Интеграция с ChatGPT** — можно уточнять запрос в диалоге, не перегенерируя каждый раз
- **Консистентность** — если вы генерируете серию в одном стиле, результаты более гармоничны

**Слабые стороны:**
- **"Гладкость"** — результаты часто выглядят слегка мультяшными, особенно в портретах
- **Меньше "художественности"** — нет того кинематографического качества, как в Midjourney
- **Дороже** — требует подписки на ChatGPT Plus

**Идеален для:**
- Концепт-арт, где важна точность деталей
- Иллюстрации с текстом
- Быстрая визуализация сложных идей

#### Midjourney

**Сильные стороны:**
- **Фотореализм** — качество картинок часто неотличимо от реальных фотографий
- **Художественность** — естественно генерирует красивые кинематографичные композиции
- **Отличные портреты** — лица получаются красивыми, с глубокими эмоциями
- **Культура сообщества** — активное сообщество художников, много шаринга техник

**Слабые стороны:**
- **Меньше контроля** — Midjourney часто игнорирует элементы запроса, если считает это более "красивым"
- **Требует более длинные промпты** — нужно описывать очень подробно
- **Дороже в длительном использовании** — требует тарифного плана

**Идеален для:**
- Портретная живопись
- Концепт-арт для киноиндустрии
- Высокохудожественный контент

#### Stable Diffusion

**Сильные стороны:**
- **Максимум контроля** — открытый исходный код, работает локально на вашем компьютере
- **Бесплатность** — после локальной установки генерация бесплатна
- **Гибкость** — множество плагинов, расширений, модифицированных версий (Realistic Vision, Dreamy Pixel Art и т.д.)
- **LoRA и DreamBooth** — возможность тонко дообучить модель на собственных данных

**Слабые стороны:**
- **Сложность** — требует техническиех навыков для оптимизации
- **Нужна мощная видеокарта** — требует NVIDIA GPU с минимум 8GB VRAM
- **Качество зависит от модели** — базовая версия хуже чем Midjourney, но финтюненые версии могут быть лучше

**Идеален для:**
- Художников с техническими навыками
- Итеративного экспериментирования
- Создания персонализированных стилей (через LoRA)
- Локальной работы (конфиденциальность)

#### FLUX (Black Forest Labs)

**Сильные стороны:**
- **Атмосферность** — естественно генерирует сложные композиции с правильной атмосферой
- **Разнообразие стилей** — хорошо работает с импрессионизмом, ретро, абстракцией
- **Скорость** — относительно быстрая генерация даже на слабых машинах

**Слабые стороны:**
- **Новая** — меньше инструментов для управления, чем у Stable Diffusion
- **Меньше контроля** — между Midjourney и Stable Diffusion

**Идеален для:**
- Экспериментов с художественными стилями
- Пейзажей и атмосфер
- Абстрактного искусства

### 2.2 Сравнительная матрица (обновлено для 2025)

| Характеристика | DALL-E 3 | Midjourney | Stable Diffusion | FLUX |
|---|---|---|---|---|
| **Качество фотореализма** | ★★★★☆ | ★★★★★ | ★★★★☆ | ★★★★☆ |
| **Художественность** | ★★★☆☆ | ★★★★★ | ★★★★★ | ★★★★★ |
| **Контроль над генерацией** | ★★★☆☆ | ★★★☆☆ | ★★★★★ | ★★★★☆ |
| **Точность текста на картинке** | ★★★★★ | ★★★☆☆ | ★★★★☆ | ★★★★☆ |
| **Стоимость** | $$$ | $$ | Free/$ | $$ |
| **Кривая обучения** | Легко | Легко | Сложно | Средне |
| **Локальное использование** | ❌ | ❌ | ✅ | ✅ (новое) |
| **Множественные подсказки (Multi-prompt)** | ❌ | ✅ | ✅ | ✅ |

***

## Модуль 3: Промпт-инжиниринг как искусство

### 3.1 От "Кот сидит на диване" к профессиональному промпту

Многие новички ошибочно думают, что достаточно просто описать, что вы хотите. На самом деле, **правильный промпт — это отдельный навык**.

**Простой промпт:**
```
"кот на диване"
```

**Результат:** случайный кот, случайный диван, случайное качество.

**Профессиональный промпт:**
```
A sleek black cat with luminous green eyes, sitting elegantly on a
velvet burgundy Victorian couch, mid-afternoon golden sunlight
streaming through tall windows, detailed oil painting style inspired
by classical portraiture, intricate whiskers and fur texture,
professional photography lighting, sharp focus, museum quality
```

**Результат:** точное, красивое, консистентное изображение.

### 3.2 Анатомия идеального промпта

Хороший промпт для нейросети имеет следующую структуру:[6][7][8]

```
[ОСНОВНОЙ СУБЪЕКТ]
[ОПИСАНИЕ ВНЕШНОСТИ/ХАРАКТЕРИСТИК]
[ОКРУЖЕНИЕ/КОНТЕКСТ]
[СТИЛЬ/ХУДОЖЕСТВЕННОЕ НАПРАВЛЕНИЕ]
[КАЧЕСТВО И ПАРАМЕТРЫ]
[ОСВЕЩЕНИЕ]
[ЭМОЦИЯ/НАСТРОЕНИЕ]
```

#### Пример разбора:

```
СУБЪЕКТ: "A female warrior with intricate armor"
        (героиня, не просто "воин")

ВНЕШНОСТЬ: "pale skin, silver hair in tight braids,
            ice-blue eyes, stern expression"
        (специфичные черты, не обобщенные)

КОНТЕКСТ: "standing on a snowy mountain peak, ancient
           magic swirling around her hands"
        (где она? что происходит?)

СТИЛЬ: "concept art for a fantasy video game, painted
        in the style of studio Ghibli and concept artists
        Jama Jurabaev"
        (указываем стиль И конкретные худож.)

КАЧЕСТВО: "highly detailed, intricate, sharp focus,
           8k resolution, professional digital art"

ОСВЕЩЕНИЕ: "golden hour sunlight casting long shadows,
            ethereal blue magical glow"

ЭМОЦИЯ: "powerful, majestic, defiant"

ФИНАЛЬНЫЙ ПРОМПТ:
A female warrior with intricate ornate armor, pale
skin, silver hair in tight braids, ice-blue eyes, and
a stern defiant expression. She stands on a snowy
mountain peak with ancient arcane magic swirling
around her hands in ethereal blue light. Concept art
in the style of Studio Ghibli and digital artist
Jama Jurabaev. Golden hour sunlight casting long
dramatic shadows. Highly detailed, sharp focus, 8k
resolution, professional quality.
```

### 3.3 Продвинутые техники промпт-инжиниринга

#### Техника "Отрицательный промпт"

Нейросети хорошо понимают, что ВЫ ХОТИТЕ видеть, но плохо понимают, что вы НЕ хотите видеть.

**Отрицательный промпт:**
```
avoid: blurry, distorted, ugly, bad anatomy, low quality,
mutated, deformed, extra limbs, watermark, text,
oversaturated, undersaturated
```

Это важно особенно для:
- Рук (ИИ часто генерирует неправильное количество пальцев)
- Текста (легко может быть нечитаемым)
- Анатомии (может быть дёрганой, неестественной)

#### Техника "Взвешивание элементов" (Weighted Prompts)

В Midjourney и Stable Diffusion можно указывать вес для разных элементов:

```
Midjourney syntax:
girl::1.5 with blue eyes::2 in a forest::0.8 --v 6

(girl важна, но синие глаза ещё важнее, лес в фоне менее важен)

Stable Diffusion syntax:
(girl:1.5) (blue eyes:2) (forest:0.8)
```

#### Техника "Стилизация через художников"

Вместо абстрактных описаний ("красиво", "красочно"), указываем конкретных художников:

```
ХУД-БЫ:
"beautiful and colorful landscape"

ПРОФЕССИОНАЛЬНО:
"landscape in the style of John Singer Sargent
and Albert Bierstadt, romanticism, impressionist
brushwork, dramatic lighting"
```

Когда вы называете реального художника, нейросеть "знает" его стиль и применяет его элементы.

### 3.4 Библиотека полезных стилистических промптов

Сохраняйте эти как шаблоны:

**Для фотореализма:**
```
photorealistic, 8k, professional photography,
sharp focus, volumetric lighting, subsurface scattering,
shot on Canon 5D mark IV with 85mm lens
```

**Для живописи масло:**
```
oil painting, impasto technique, Renaissance style,
museum masterpiece, gilded frame, dramatic chiaroscuro,
detailed brushwork, dramatic lighting
```

**Для иллюстрации детской книги:**
```
children's book illustration, storybook art,
soft colors, warm lighting, cute characters,
gentle whimsical style, pencil and watercolor
```

**Для концепт-арта:**
```
concept art, digital painting, dramatic lighting,
cinematic composition, professional quality,
trending on artstation, by studio artists
```

**Для киноэстетики:**
```
cinematography, cinematic lighting, professional
color grading, depth of field, shot as a
film by Wes Anderson / Guillermo del Toro /
Stanley Kubrick [выбрать режиссёра]
```

### 3.5 Антипаттерны — что НЕ делать

❌ **"Make it beautiful"** — слишком абстрактно
✅ **"Dramatic lighting, vibrant colors, sharp details"** — конкретнее

❌ **"High quality"** — предполагается по умолчанию
✅ **"8k, sharp focus, professional digital art"** — специфичнее

❌ **"Art style by AI"** — неизвестно, какой стиль
✅ **"In the style of Simon Stalenhag and Beeple"** — известные художники

❌ **Слишком длинный промпт (>500 слов)** — модель теряет фокус
✅ **150-300 слов оптимально** — достаточно информации, не перегруженно

***

## Модуль 4: Техники редактирования и контроля генерации

### 4.1 ControlNet: ваш новый лучший друг

**ControlNet** — это революционная архитектура, которая дает вам **точный контроль** над генерацией. Вместо надежды, что ИИ сгенерирует то, что вы хотите, вы **показываете ему**, что хотите.[9][10][11]

**Как это работает:**
1. Вы загружаете исходное изображение
2. Выбираете модель ControlNet, которая вас интересует
3. ControlNet анализирует это изображение и извлекает нужную информацию
4. Вы добавляете текстовый промпт
5. Нейросеть генерирует новое изображение, **сохраняя информацию из исходного**

#### Семь основных моделей ControlNet:

**1. Canny (Канты/Края)**

Извлекает контуры и края из изображения.

**Применение:**
- Вы хотите сохранить композицию фотографии, но изменить стиль
- Нужно скопировать позу с одной фотографии на другую
- Хотите переделать дизайн интерьера, но оставить общую структуру

**Пример:** фото обычного дома → генерируем дом в стиле Хогвартса, сохраняя архитектуру

**2. Depth Map (Карта глубины)**

Анализирует, какие объекты близко, какие далеко.

**Применение:**
- Нужна правильная перспектива
- Хотите сгенерировать сложную сцену с несколькими планами
- Важна глубина композиции

**Пример:** фото людей в комнате → генерируем фэнтези-зал, сохраняя расположение предметов в пространстве

**3. OpenPose (Скелет/Поза)**

Определяет положение человека (где руки, ноги, голова).

**Применение:**
- Вы хотите использовать позу одного человека, но изменить его внешность
- Нужна конкретная поза для персонажа
- Переносим позу с фотографии на сгенерированного персонажа

**Пример:** фото вас в интересной позе → генерируем себя как эльфа, ковбоя, астронавта — в той же позе

**4. HED (Holistically-Nested Edge Detection)**

Мягче чем Canny, более "естественные" контуры.

**Применение:**
- Нужно сохранить композицию, но мягче
- Перекраска или изменение стиля
- Более художественное переопределение

**5. Scribble (Эскиз)**

Работает с вашим собственным рисунком (даже очень грубым).

**Применение:**
- Вы набросали эскиз карандашом — нейросеть его "доделает"
- Вычерчиваете композицию линиями — нейросеть добавляет детали и текстуру
- Комбинируете ручное рисование с ИИ

**Пример:** вы рисуете stick-figure позу → нейросеть генерирует красивого персонажа в этой позе

**6. Normal Map (Нормальная карта)**

Информация о том, как свет падает на поверхность.

**Применение:**
- Сохранение трехмерной информации
- Генерация текстур с правильным освещением
- 3D-подобные результаты из 2D

**7. Semantic Segmentation (Семантическая сегментация)**

Понимает, что на картинке (небо, земля, люди, машины и т.д.).

**Применение:**
- Очень точный контроль над конкретными элементами
- Можно говорить: "небо голубое, земля зеленая, люди в красном"
- Максимальный контроль для сложных сцен

### 4.2 Workflow для профессиональной работы

**Рабочий процесс 1: От фотографии к фэнтези**

```
1. Возьмите фотографию (себя, друга, натуру)
2. Используйте OpenPose ControlNet для извлечения позы
3. Напишите промпт: "elf warrior with magical powers,
   fantasy armor, glowing runes"
4. Генерируйте в нужной позе, но с новой внешностью
5. Используйте Inpainting в Photoshop для финальных правок
```

**Рабочий процесс 2: От скетча к полной иллюстрации**

```
1. Нарисуйте скетч в Procreate/Photoshop (даже грубый)
2. Используйте Scribble ControlNet
3. Генерируйте несколько вариантов в разных стилях
4. Выберите лучший вариант
5. Доработайте в Photoshop детали, цвета, свет
```

**Рабочий процесс 3: Консистентный персонаж**

```
1. Сгенерируйте персонажа (например, "elf mage")
2. Экспортируйте изображение
3. Используйте DreamBooth или LoRA на Stable Diffusion
   для обучения "этого конкретного персонажа"
4. Теперь можете генерировать этого персонажа в разных
   сценах, позах, стилях
5. Создаёте сюжет или серию с консистентным персонажем
```

### 4.3 Инпейнтинг и аутпейнтинг

**Inpainting (Вписывание)** — замена части изображения новым контентом с сохранением остального.

**Применение:**
- Замена лица в изображении
- Удаление нежелательного объекта
- Добавление деталей
- Исправление ошибок ИИ (например, неправильные руки)

**Инструменты:**
- Photoshop с плагинами для ИИ
- Web-интерфейсы Stable Diffusion (AUTOMATIC1111, ComfyUI)
-专ованные сервисы как Cleanup.pictures

**Outpainting (Расширение)** — расширение изображения за его границы.

**Применение:**
- Кадрирование было слишком тесным? Расширьте!
- Нужно поместить объект в больший контекст
- Продление панорамы

**Пример:**
```
Исходное изображение: человек в кадре по пояс
Outpainting: генерируем нижнюю часть тела, фон сзади
Результат: человек во весь рост на фоне пейзажа
```

***

## Модуль 5: Дообучение моделей: LoRA и DreamBooth

### 5.1 Введение в персонализацию

Что если вы хотите:
- Всегда иметь возможность генерировать **себя** в разных сценах?
- Создать уникальный **артстиль**, который только у вас?
- Научить модель вашему **визуальному почерку**?

Для этого существуют **LoRA** и **DreamBooth**.[12][13]

### 5.2 DreamBooth: персонализация на стероидах

**DreamBooth** — метод, который обучает модель **вашему конкретному объекту** (лицу, стилю, объекту) на минимальном наборе данных (5-20 изображений).

**Как это работает:**

1. Вы предоставляете 10-15 фотографий себя (или чего-то другого)
2. DreamBooth находит "уникальный токен" для вас в латентном пространстве модели
3. Обучение происходит быстро (10-30 минут на GPU)
4. Теперь вы можете генерировать себя в **любых сценах, позах, стилях**

**Практический пример:**

```
Исходные фото: 15 селфи в разных условиях
Обучение: "человек [V] в DreamBooth"
Генерируемые команды:
- "а portrait of [V] as an astronaut"
- "[V] dancing in a ballroom in Victorian era"
- "[V] as a fantasy wizard"
- "oil painting of [V] by Rembrandt"

Результат: ВЫ в разных воплощениях, но узнаваемо ВЫ
```

### 5.3 LoRA: легкая и быстрая адаптация

**LoRA** (Low-Rank Adaptation) — более лёгкая версия DreamBooth.

**Отличия:**
- DreamBooth обновляет **все параметры** модели (занимает 2-4GB памяти)
- LoRA добавляет **лёгкие адаптеры** (занимает 50-100MB)
- LoRA быстрее обучается и быстрее применяется
- LoRA не требует нормализирующих изображений

**Для чего использовать LoRA:**

1. **Персонализированный стиль**
   - Вы любите определённый стиль живописи? Обучите LoRA на 30 изображениях в этом стиле
   - Теперь любой ваш промпт будет в этом стиле

2. **Персонаж/лицо**
   - Обучите LoRA на фотографиях конкретного человека
   - Можете генерировать этого человека в любых сценах

3. **Концепт/объект**
   - Ваша кошка? Обучите LoRA на 20 фото вашей кошки
   - Генерируйте вашу кошку в разных ситуациях

**Процесс обучения LoRA (упрощённо):**

```
Данные: 10-30 изображений (лица/стили/объекты)
Параметры:
  - Learning rate: 0.0001
  - Batch size: 1-4
  - Epochs: 100-1000
  - Resolution: 512x512 или 768x768

Результат: файл .safetensors (50-100MB)
```

### 5.4 Текстурные инверсии (Textual Inversion)

Для тех, кто не хочет обучать всю LoRA, есть **текстурные инверсии** — обучение работает с текстовым "токеном", а не с весами модели.

**Применение:**
- Обучить модель на конкретном стиле за 30 минут
- Результат: маленький файл (100KB)
- Использование: просто добавляете `<style>` в промпт

***

## Модуль 6: Этика, авторские права и практические рекомендации

### 6.1 Вопрос авторства: кто владеет сгенерированным изображением?

Это **самый сложный вопрос** в мире ИИ-искусства в 2025-2026 годах, и ответ остаётся неопределённым.[14][15][16]

#### Разные юрисдикции, разные ответы:

**В США:**
- U.S. Copyright Office временно не признаёт авторские права на чистом выходе ИИ (без человеческого творчества)
- НО если вы "значительно" изменили изображение (в Photoshop, добавили руками) — это может быть защищено

**В России:**
- По статье 1261 ГК РФ, некоторые юристы считают, что авторские права могут принадлежать **разработчику программы** (создателю нейросети)
- Другие считают, что пользователь, создавший промпт, — это автор
- **В реальности: это не решено и не ясно**

**В ЕС:**
- Идёт активное законодательство (AI Act)
- Тренд: требование указывать "использовано ИИ-содержимое"

#### Практический совет для художников 2025-2026:

```
ИСПОЛЬЗОВАНИЕ СГЕНЕРИРОВАННОГО КОНТЕНТА:

✅ БЕЗОПАСНО:
- Личное использование (для портфолио, демонстрации)
- Редактирование и комбинирование (юристы склоняются к тому, что это "трансформативное использование")
- Использование как базы для ручной доработки (если вы потом дорисовали/переделали значительно)

⚠️ СЕРАЯ ЗОНА:
- Коммерческое использование прямого выхода ИИ
- Продажа сгенерированных NFT-коллекций (нужны уточнения)
- Использование в книгах/публикациях

❌ ИЗБЕГАЙТЕ:
- Выдавать сгенерированное ИИ за полностью ручное рисование
- Использовать сгенерированное для коммерческой конкуренции художникам
- Обучать свои модели на заимствованных изображениях
```

### 6.2 Этические рекомендации

**Прозрачность:**
- Если вы публикуете ИИ-контент, **указывайте, что это ИИ**
- "Created with AI assistance" или "AI-generated elements"
- Это не только этично, но и становится требованием закона

**Авторство оригинального контента:**
- Модели DALL-E, Midjourney были обучены на реальных картинках художников
- Когда вы используете ИИ, вы опосредованно используете их работу
- Это не означает, что вы не имеете права на использование, но помните об этом

**Честная конкуренция:**
- Если вы предлагаете услугу "создание искусства" — не скрывайте, что используете ИИ
- Помещайте ИИ-контент в "ИИ-категорию" конкурсов
- Не участвуйте в конкурсах, где явно запрещён ИИ, с ИИ-контентом

***

## Модуль 7: Практический рабочий процесс художника 2025-2026

### 7.1 День из жизни цифрового художника с ИИ

**Сценарий: концепт-художник для видеоигры**

```
09:00 — Утренний брифинг
Дизайнер говорит: "Нужен энхобарбус-ублюдок, враг игрока.
Его характер: уверенный, опасный, ненавидит честность."

09:30 — Быстрая визуализация (10 минут с Midjourney)
Промпт: "a confident, scarred warlord with eastern influences,
dark corrupted armor, intricate tattoos, menacing presence,
concept art, dramatic lighting"
Генерирую 4 варианта
Выбираю лучший: https://imgur.com/abc123.jpg

10:00 — Уточнение деталей (30 минут)
Загружаю в AUTOMATIC1111 (локальный Stable Diffusion)
Используя ControlNet OpenPose, переделываю позу
Меняю детали доспеха через LoRA "evil-armor-style"
Генерирую 8 вариантов

10:30 — Доработка в Photoshop (1 час)
- Добавляю детали (меньше вмешательства = более честно)
- Уточняю лицо
- Добавляю цветовой баланс
- Добавляю уникальные элементы (родимое пятно, шрамы)

11:30 — Демонстрация команде
"Вот три варианта концепта. Для варианта B предлагаю
сделать позу более угрожающей через ControlNet."

12:00 — Фидбек и итерация (1 час)
Геймдизайнер: "Доспех слишком азиатский, нужнее средневековье"
Меняю LoRA, генерирую новые варианты
Выбираем финальный вариант

13:00 — Финал
Экспортирую высокоразрешённое изображение (8k)
Отправляю 3D-художнику для модельки
```

**Результат:** за 4 часа сделано то, что раньше заняло бы день-два.

### 7.2 День из жизни иллюстратора детских книг

```
09:00 — Идеация
Автор рассказал историю про маленького дракончика.
Мне нужно создать серию иллюстраций.

09:30 — Дизайн персонажа (с ИИ)
Генерирую несколько вариантов маленького дракончика
Выбираю лучший
Обучаю на нём DreamBooth LoRA за 20 минут

10:00 — Сценарий 1: дракончик просыпается
Промпт: "a cute, friendly little dragon [DreamBooth token]
waking up in a cozy cave, morning light, children's book
illustration style, soft watercolors"
Генерирую 4 варианта
Выбираю и импортирую в Procreate

10:30 — Ручное улучшение (30 минут)
Добавляю детали в Procreate
Улучшаю цветовую палитру
Добавляю уникальные стили

11:00 — Сценарий 2: приключение
Промпт: "my little dragon [token] having an adventure
in a magical forest, meeting woodland creatures,
children's book aesthetic"
Повторяю процесс

15:00 — Итого: 6 иллюстраций за день

Раньше это заняло бы неделю ручной работы!
```

### 7.3 Студийный workflow для commercial artwork

**Для работы на клиента:**

```
1. БРИФИНГ (30 минут)
   - Понимаю видение клиента
   - Собираю референсы
   - Обсуждаю стиль, настроение

2. БЫСТРЫЕ ВАРИАНТЫ (1-2 часа)
   - Генерирую 20-30 вариантов в разных стилях
   - Каждый вариант занимает 1-2 минуты
   - Отправляю лучшие 5-6 вариантов клиенту

3. ВЫБОР И ИТЕРАЦИЯ (1 час)
   - Клиент выбирает направление
   - Генерирую 10 вариантов в выбранном стиле
   - Уточняю детали через ControlNet

4. ФИНАЛЬНАЯ ДОРАБОТКА (2-4 часа)
   - Ручное редактирование в Photoshop
   - Добавление деталей, корректировка
   - Цветовая коррекция
   - Экспорт

5. ДОСТАВКА
   - Final artwork в 300dpi
   - Исходный файл для клиента
```

**Экономика:**
- Раньше: 3-5 дней работы → $2000-5000
- Теперь: 8-12 часов работы → можно взять $2000-5000 (более высокий доход/час) или конкурировать на цене ($1000-2000)

***

## Модуль 8: Расширенные техники и экспериментирование

### 8.1 Комбинирование нескольких ControlNet

В 2025 году можно комбинировать несколько ControlNet одновременно:

```
Пример: Multi-ControlNet
- Canny ControlNet для композиции
- OpenPose ControlNet для позы
- Depth ControlNet для перспективы

Результат: ПОЛНЫЙ контроль над генерацией
```

### 8.2 Комбинирование разных нейросетей

```
Workflow:
1. Midjourney генерирует красивый портрет
2. Экспортирую в Stable Diffusion + ControlNet OpenPose
3. Меняю позу, сохраняя лицо
4. Возвращаюсь в Midjourney для финальной полировки
5. Доделываю в Photoshop

Результат: лучшее от каждой модели!
```

### 8.3 Создание видео с ИИ

В 2025-2026 годах видео-генерация становится реальностью:

- **Runway Gen-3** — генерация видео из текста
- **Sora** — OpenAI видео-модель
- **Pika** — видео из одного изображения

**Практическое применение:**
```
1. Создаёте серию иллюстраций через Midjourney
2. Импортируете в Runway
3. Генерируете анимацию между кадрами
4. Добавляете музыку и звук
5. Получаете мини-фильм!
```

***

## Модуль 9: Рынок и экономика AI-искусства в 2025-2026

### 9.1 Где можно заработать

**Нишевые возможности:**

1. **Персонализированный портрет**
   - Клиент предоставляет фото
   - Вы генерируете портрет в стиле Ван Гога/как викинг/как фея/как супергерой
   - Цена: $50-500 за портрет
   - Время: 30 минут - 1 час

2. **Коммерческие иллюстрации**
   - Компаниям нужны иллюстрации для маркетинга
   - ИИ + ручная доработка = быстро и качественно
   - Цена: $500-5000 за проект
   - Время: 4-16 часов

3. **Концепт-арт для гейм-девелопмента**
   - Game studios нанимают концепт-художников
   - ИИ ускоряет быстрое создание идей
   - Обучение на конкретном стиле студии через LoRA
   - Зарплата: $50k-120k/год

4. **NFT и крипто-коллекции**
   - Нишевый, но всё ещё существующий рынок
   - Создание уникальных AI-генерированных коллекций
   - Цена: $100-1000+ за NFT

5. **Обучение других художников**
   - Курсы по промпт-инжинирингу
   - Мастер-классы по использованию ControlNet
   - Курс: $200-2000
   - Потенциал: 100+ студентов

6. **Плагины и инструменты**
   - Создание специализированных LoRA для конкретных стилей
   - Продажа через Civitai или itch.io
   - Цена: $5-50 за LoRA
   - Потенциал: 1000+ покупок

### 9.2 Факторы конкуренции

```
2023-2024: "ИИ-художник может заработать просто генерируя"
2025-2026: "нужно быть лучше, чем ИИ, используя ИИ"
```

**Барьеры входа исчезают**, поэтому конкуренция растёт. Но это открывает и новые возможности:

- Художник + ИИ > художник или ИИ по отдельности
- Стиль, оригинальность, понимание композиции — остаются критичны
- Скорость работы возросла в 10x, поэтому можно брать больше проектов

***

## Модуль 10: Будущее AI-искусства и карьерные перспективы

### 10.1 Прогнозы для 2026-2028

**Что наверняка произойдёт:**

1. **Видео-генерация станет основным инструментом**
   - Не только изображения, но полные сцены с движением
   - Это революционизирует кино, телевидение, маркетинг

2. **Персональные ИИ-ассистенты**
   - Вы дообучаете ИИ на собственных работах
   - Он становится продолжением вашего стиля
   - Как виртуальный ассистент-художник

3. **Реальное время генерация**
   - Во время streaming рисования, ИИ помогает рисовать
   - VR/AR интеграция

4. **Юридическое уточнение**
   - Законы о авторстве станут ясными
   - Вероятнее всего: признание прав за пользователем с указанием ИИ

### 10.2 Карьерные пути для художников в 2025-2026

**Путь 1: Гибридный художник**
```
Совмещаете традиционные навыки с ИИ
Зарплата: $60k-120k/год
Спрос: ВЫСОКИЙ
Стабильность: ВЫСОКАЯ
```

**Путь 2: ИИ-специалист для индустрии**
```
Game developer, movie studio, advertising
Обучаетесь на специализированных LoRA
Создаёте инструменты и pipelines
Зарплата: $80k-150k/год
Спрос: ОЧЕНЬ ВЫСОКИЙ
Стабильность: ВЫСОКАЯ
```

**Путь 3: Фрилансер-предприниматель**
```
Продаёте персонализированные услуги
Создаёте инструменты и LoRA
Обучаете других
Потенциал дохода: $100k-500k+/год
Спрос: СРЕДНИЙ (зависит от маркетинга)
Стабильность: СРЕДНЯЯ (но потенциал выше)
```

**Путь 4: Создатель контента**
```
YouTube, TikTok, Instagram про ИИ-искусство
Курсы и мастер-классы
Монетизация: Patreon, YouTube, продажа курсов
Потенциал: $50k-300k+/год
Спрос: СРЕДНИЙ-ВЫСОКИЙ
Стабильность: ЗАВИСИТ ОТ ВИРАЛЬНОСТИ
```

### 10.3 Компетенции, которые остаются критичны

Даже с развитием ИИ, эти навыки не исчезнут:

```
✓ Композиция и дизайн
✓ Понимание света и тени
✓ Цветовая теория
✓ Анатомия и пропорции
✓ Историческое знание искусства
✓ Коммуникация (понимание briefs)
✓ Критическое мышление (оценка результатов)
✓ Оригинальность и творчество (идеи)
```

**ИИ НЕ ЗАМЕНИТ эти навыки.** ИИ — просто инструмент для их реализации.

***

## Практический экзамен для студентов

### Задача 1: Создание персонажа (1 час)

```
Требования:
1. Используя DALL-E 3 или Midjourney, создайте персонажа:
   - Фэнтези-воин женского пола
   - Конкретный культурный контекст (славянский, арабский, японский)
   - Описание внешности: возраст, черты лица, уникальные элементы

2. Напишите промпт (150-300 слов)

3. Сгенерируйте минимум 3 варианта

4. Выберите лучший и отредактируйте в Photoshop/Procreate
   (добавив свои детали)

5. Дайте описание творческого процесса

Оценивается: детализация промпта, качество результата,
уникальность персонажа, уровень ручной доработки
```

### Задача 2: ControlNet практика (1.5 часа)

```
Требования:
1. Выберите одно из:
   - Фото себя → создайте себя как фэнтези-персонажа (OpenPose)
   - Фото комнаты → переделайте её интерьер в другом стиле (Depth/Canny)
   - Собственный набросок → развейте его в полную иллюстрацию (Scribble)

2. Используйте Stable Diffusion + ControlNet локально
   (или Web-интерфейс ComfyUI)

3. Создайте 5 итераций, каждая лучше предыдущей

4. Экспортируйте финальный результат 8k

Оценивается: техническое мастерство, творчество, контроль
над процессом, улучшение от итерации к итерации
```

### Задача 3: LoRA/DreamBooth (2 часа)

```
Требования:
1. Соберите 15-20 изображений (себя, объекта, стиля)

2. Обучите LoRA на Stable Diffusion (через web-интерфейс или локально)

3. Создайте 5 разных изображений, используя обученную LoRA

4. Напишите документацию:
   - Как обучали
   - Какие параметры использовали
   - Результаты

Оценивается: консистентность результатов, качество LoRA,
правильность параметров, документация
```

***

## Заключение: Художник 2025-2026 года

Художник XXI века — это не тот, кто лучше всех рисует рукой. Это тот, кто:

1. **Понимает** вашу видеть и передать видение
2. **Планирует** процесс для максимальной эффективности
3. **Командует** ИИ, а не наоборот
4. **Редактирует** и улучшает результаты
5. **Создаёт** оригинальное, что-то, чего раньше не было

ИИ-инструменты — это не опасность, это **освобождение от мелкой работы** и возможность сосредоточиться на **том, что действительно важно: на идеях, композиции, визуальном повествовании**.

Художники, которые в 2026 году будут наиболее востребованы — это те, кто принял ИИ не как конкурента, а как **партнера** в творчестве.

**Практический совет напоследок:**

```
Начните прямо сейчас:

День 1-3: Экспериментируйте с Midjourney/DALL-E
День 4-7: Изучите ControlNet
День 8-14: Обучите собственную LoRA
День 15+: Интегрируйте в собственный рабочий процесс

За месяц вы получите навыки, которые художников раньше
учили годами.
```

Добро пожаловать в будущее искусства. 🎨🤖

***

## Полезные ресурсы для дальнейшего обучения

### Платформы для генерации

- **Midjourney**: https://midjourney.com
- **DALL-E 3**: https://openai.com (через ChatGPT Plus)
- **Stable Diffusion WebUI**: https://github.com/AUTOMATIC1111/stable-diffusion-webui
- **ComfyUI**: https://github.com/comfyanonymous/ComfyUI
- **Runway**: https://runway.com

### Обучение и комьюнити

- **Civitai**: https://civitai.com (сообщество, LoRA, модели)
- **Hugging Face**: https://huggingface.co (модели, датасеты)
- **r/StableDiffusion**: https://reddit.com/r/StableDiffusion
- **YouTube каналы**: "Olivio Sarikas", "Holger Ballmann" (ControlNet туториалы)

### Образовательные курсы

- **Fast.ai**: Практическое обучение
- **Coursera**: Advanced ML и Computer Vision
- **Udemy**: Множество курсов по ИИ-искусству (проверьте рейтинги)

***

**Конец курса. Творите смело!** 🚀

## Сноски

[1](https://ai2people.com/ru/ai-art-genrators/)
[2](https://vc.ru/ai/2165114-luchshie-nejroseti-dlya-sozdaniya-artov-2025)
[3](https://habr.com/ru/articles/899442/)
[4](https://habr.com/ru/companies/selectel/articles/691226/)
[5](https://incrypted.com/top-nejrosetej-dlja-generacii-kartinok-nft-po-opisaniju/)
[6](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0_%D0%BF%D0%BE%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%BE%D0%BA)
[7](https://developers.sber.ru/docs/ru/gigachat/prompts-hub/prompt-engineering)
[8](https://habr.com/ru/articles/956596/)
[9](https://habr.com/ru/companies/ruvds/articles/719348/)
[10](https://t-j.ru/controlnet/)
[11](https://www.youtube.com/watch?v=yEep-3UIJsY)
[12](https://blog.segmind.com/dreambooth-lora-understanding-fine-tuning-parameters/)
[13](https://www.reddit.com/r/StableDiffusion/comments/18rsqdn/need_help_what_is_difference_between_training_and/)
[14](https://xn--80adjuraahjdpw.xn--p1ai/blog/avtorskie-prava-na-kartinki-iz-nejroseti)
[15](https://metranpage.com/legal-ai)
[16](https://ezybrand.ru/blog/avtorskie-prava-na-kontent-nejrosetej/)
[17](https://moge.ai/ru/product/wonder-ai-art-generator)
[18](https://www.youtube.com/watch?v=6glHekd25nE)
[19](https://selectel.ru/blog/ai_overview/)
[20](https://dtf.ru/top-smm/3066060-20-neirosetei-dlya-izmeneniya-izobrazhenii-v-2025-godu)
