# Fine-tuning: обучение модели под свои задачи

**Fine-tuning** (дообучение) — это процесс дополнительного обучения уже обученной модели на твоих специфических данных, чтобы она лучше справлялась с конкретными задачами.

Представь, что у тебя есть универсальный переводчик, который знает много языков. Fine-tuning — это как дать ему дополнительный курс по медицинской терминологии, чтобы он лучше переводил медицинские тексты.

## Зачем нужен fine-tuning?

Готовая модель (например, GPT-4) обучена на общих данных и хорошо работает для многих задач. Но для специфических задач она может:
- Не знать терминологию твоей области
- Не понимать контекст твоих данных
- Давать ответы не в нужном формате
- Не следовать твоим правилам и стилю

Fine-tuning решает эти проблемы, обучая модель на твоих примерах.

## Как работает fine-tuning?

1. **Подготовка данных**: собираешь примеры "вопрос-ответ" или "вход-выход" для своей задачи
2. **Форматирование**: данные приводятся в нужный формат для обучения
3. **Обучение**: модель дообучается на твоих данных (обычно это занимает часы или дни)
4. **Тестирование**: проверяешь, как модель работает на новых примерах
5. **Деплой**: используешь дообученную модель в своём приложении

## Примеры использования

### Специфическая терминология
Дообучить модель понимать термины твоей компании или отрасли.

### Специфический формат ответов
Научить модель отвечать в определённом формате (JSON, таблицы, структурированные данные).

### Стиль и тон
Научить модель писать в нужном стиле (формальный, дружелюбный, технический).

### Доменная экспертиза
Дообучить модель на данных из твоей области (медицина, право, финансы).

## Технические детали

### Данные для обучения
Обычно нужно:
- Минимум: несколько сотен примеров
- Оптимально: несколько тысяч примеров
- Формат: JSONL (JSON Lines) с парами "prompt" и "completion"

### Процесс обучения
- Используется transfer learning: берётся предобученная модель
- Обновляются веса модели на твоих данных
- Обычно замораживаются ранние слои, обучаются только последние

### Стоимость
- OpenAI Fine-tuning: платишь за обучение и за использование модели
- Self-hosted: нужны GPU и время

## Альтернативы fine-tuning

### Few-shot learning
Показывать примеры прямо в промпте — проще, но менее эффективно для больших объёмов специфических данных.

### RAG
Использовать внешние данные через RAG — хорошо для актуальной информации, но не меняет поведение модели.

### Prompt engineering
Тщательно настраивать промпты — бесплатно, но ограничено возможностями базовой модели.

## Когда использовать fine-tuning?

✅ Много специфических примеров (тысячи)
✅ Нужен специфический формат или стиль
✅ Задача повторяется часто
✅ Нужна высокая точность в узкой области

❌ Мало данных (меньше сотни примеров)
❌ Задача меняется часто
❌ Можно решить через промпты или RAG

## Пример workflow

```python
# 1. Подготовка данных
training_data = [
    {"prompt": "Переведи на медицинский: головная боль",
     "completion": "цефалгия"},
    # ... больше примеров
]

# 2. Форматирование и загрузка
# 3. Запуск fine-tuning через API
# 4. Ожидание завершения
# 5. Тестирование новой модели
# 6. Использование в приложении
```

## Ограничения

- **Стоимость**: обучение и использование дообученной модели дороже
- **Время**: обучение может занять часы или дни
- **Данные**: нужно много качественных примеров
- **Переобучение**: модель может "запомнить" твои данные вместо обобщения

## Уровень
3

## Примеры из жизни
- Дообучение модели для поддержки клиентов с базой знаний компании
- Создание специализированного переводчика для медицинских текстов
- Обучение модели генерировать код в стиле команды
- Создание чат-бота с корпоративным стилем общения

## Полезные ссылки для этого уровня
- [OpenAI Fine-tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)
- [Fine-tuning Best Practices](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)

## Заметки
